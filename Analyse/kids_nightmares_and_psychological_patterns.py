# -*- coding: utf-8 -*-
"""kids nightmares and psychological patterns.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oNOAGdy0b14U3ss4DbZR-a33aVbSFwC8
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# Load the dataset into a pandas DataFrame
df = pd.read_csv("/path/to/your/nightmare_dataset.csv")  # Update with the correct path to your dataset

# Display unique values and their counts for each column
for column in df.columns:
    print(f"Value counts for '{column}':")
    print(df[column].value_counts(dropna=False))
    print("\n")

# Check for missing values
missing_values = df.isnull().sum()

# Display columns with missing values
print("Missing values in each column:")
print(missing_values)

# # Remove rows with missing values
# df = df.dropna()

# Remove rows where 'Age' is equal to 24
df = df[df['Age'] != 24]

# After removing, check the number of missing values
missing_values_after_removal = df.isnull().sum()

# Show the cleaned dataset and missing values count
print("Missing values after removal:")
print(missing_values_after_removal)
print("\nCleaned DataFrame shape:", df.shape)# Display unique values for each column

import pandas as pd

print(df['Age'].head(10))  # Show first 10 values
print(df['Age'].dtype)  # Show the data type of the column

print(df['Age'].unique())  # Show unique values

# Ensure 'Age' column is numeric (ignoring errors for non-convertible values)
df['Age'] = pd.to_numeric(df['Age'], errors='coerce')

# Define the bins for Age
age_bins = [3, 5, 7, 10]
age_labels = ['4-5 years', '6-7 years', '8-10 years']

# Apply binning using pd.cut()
df['Age Category'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=True)

# Check the modified Age column
print(df[['Age', 'Age Category']].head())

# Display unique values and their counts for each column
print("\nValue counts for 'Age Category':")
print(df['Age Category'].value_counts(dropna=False))

# Print the unique values in the 'Nightmare Content' column
unique_nightmare_content = df['Nightmare Content'].unique()
print("Unique values in 'Nightmare Content':")
print(unique_nightmare_content)

# Define a function to categorize the 'Nightmare Content'
def categorize_nightmare_content(content):
    if content in ['Being Chased', 'Monster in Room', 'Monster Under Bed', 'Scary Place Fear', 'Darkness Fears', 'Animals attacking']:
        return 'Fear-based'
    elif content in ['Losing Someone', 'Losing Body Parts', 'Losing Control']:
        return 'Loss-based'
    elif content in ['Fire Burning', 'Water Drowning', 'Falling from Edge', 'Falling from Height', 'Zombie Attack']:
        return 'Danger-based'
    elif content in ['School Test Failure', 'Parents Fights', 'Parental Slap Fear']:
        return 'Social-based'
    else:
        return 'Miscellaneous'

# Apply the categorization function to the 'Nightmare Content' column
df['Nightmare Content'] = df['Nightmare Content'].apply(categorize_nightmare_content)

# Print the first few rows to check the result
print(df[['Nightmare Content']].head())
print(df['Nightmare Content'].value_counts(dropna=False))
# After removing, check the number of missing values
missing_values_after_removal = df.isnull().sum()

# Show the cleaned dataset and missing values count
print("Missing values after removal:")
print(missing_values_after_removal)

import pandas as pd

# Define a function to categorize the 'Parental Observations'
def categorize_parental_observations(observation):
    # Check if the value is NaN and return NaN so it can be imputed later
    if pd.isna(observation):
        return observation  # This will return NaN to leave it for later imputation
    if observation in ['Monster Under Bed', 'Monster in Room', 'Being Chased', 'Scary Place Fear', 'Darkness Fears', 'Animals attacking']:
        return 'Fear-based'
    elif observation in ['Losing Body Parts']:
        return 'Loss-based'
    elif observation in ['Falling from Height', 'Trapped in Space', 'Parents Fights']:
        return 'Danger-based'
    elif observation in ['School Test Failure', 'Parental Slap Fear']:
        return 'Social-based'
    else:
        return 'Miscellaneous'

# Apply the categorization function to the 'Parental Observations' column
df['Parental Observations'] = df['Parental Observations'].apply(categorize_parental_observations)

# Print the first few rows to check the result
print(df[['Parental Observations']].head())

# After removing, check the number of missing values
missing_values_after_removal = df.isnull().sum()

# Show the cleaned dataset and missing values count
print("Missing values after removal:")
print(missing_values_after_removal)

# Define a function to categorize the 'Recent Life Changes'
def categorize_recent_life_changes(change):
    if pd.isna(change):
        return (change)  # This will return NaN to leave it for later imputation
    if change in ["Parent's job loss", "Parents' recent divorce", "New sibling born"]:
        return 'Family-related changes'
    elif change in ['Starting kindergarten', 'Academic pressure', 'Started daycare']:
        return 'School-related changes'
    elif change == 'Recent move to new house':
        return 'Household-related changes'
    else:
        return 'No changes'

# Apply the categorization function to the 'Recent Life Changes' column
df['Recent Life Changes'] = df['Recent Life Changes'].apply(categorize_recent_life_changes)

# Print the first few rows to check the result
print(df[['Recent Life Changes']].head())

# Print the unique values in the 'Sleep Environment' column
unique_sleep_environment = df['Sleep Environment'].unique()
print("Unique values in 'Sleep Environment':")
print(unique_sleep_environment)

# Define a function to categorize the 'Sleep Environment'
def categorize_sleep_environment(env):
    if pd.isna(env):
        return (env)  # This will return NaN to leave it for later imputation
    if env in ['Curtains blowing', 'Window open', 'Torn wallpaper', 'Creaking floor']:
        return 'Environmental factors'
    elif env in ['Soft nightlight', 'Nightlight absent', 'Dark room']:
        return 'Light-related factors'
    elif env in ['Clown statue', 'Ghostly figure', 'Abandoned toys']:
        return 'Fear-inducing objects'
    else:
        return 'Shared space'

# Apply the categorization function to the 'Sleep Environment' column
df['Sleep Environment'] = df['Sleep Environment'].apply(categorize_sleep_environment)

# Print the first few rows to check the result
print(df[['Sleep Environment']].head())

# Define the binning strategy
bins = [7, 15, 25, 35]
labels = ['Low', 'Medium', 'High']

# Perform the binning and update the 'Psychological Problems at School' feature directly
df['Psychological Problems at School'] = pd.cut(df['Psychological Problems at School'], bins=bins, labels=labels, right=True)

# Check the unique values of the modified column
print("Unique values in 'Psychological Problems at School' after binning and removing NaN rows:")
print(df['Psychological Problems at School'].unique())

import numpy as np

# Replace 'Miscellaneous' with NaN in the 'Nightmare Content' column
df['Nightmare Content'] = df['Nightmare Content'].replace('Miscellaneous', np.nan)

# Check the result
print(df[['Nightmare Content']].head())


# Print the unique values for each column (feature)
for column in df.columns:
    unique_values = df[column].unique()
    print(f"Unique values in '{column}':")
    print(unique_values)
    print("-" * 50)

import numpy as np
from sklearn.cluster import KMeans
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

# Make a copy of the dataset to work on
df_copy = df.copy()

# Define columns that do not require label encoding
no_encoding_columns = ['Has Recent Life Changes', 'Irregular Sleep Pattern', 'Fear-Related Nightmare']

# Initialize a dictionary to store label encoders
label_encoders = {}

# Apply label encoding to columns that need it
for column in df_copy.columns:
    if column not in no_encoding_columns:
        encoder = LabelEncoder()
        df_copy[column] = encoder.fit_transform(df_copy[column].astype(str))
        label_encoders[column] = encoder  # Store the encoder for inverse transformation later

# Now, create a mask for missing values
# missing_mask = df_copy.isna()

# 2. Identify columns with missing values
missing_columns = df_copy.columns[df_copy.isna().any()].tolist()

# 3. Create a copy of the dataframe to perform KMeans imputation on
df_copy_imputed = df_copy.copy()

# For each column with missing values, apply KMeans clustering
for column in missing_columns:
    missing_mask = df_copy_imputed[column].isna()

    if missing_mask.any():  # Check if there are missing values in the column
        # Use only the rows that are not missing for this column
        known_values = df_copy_imputed[~missing_mask]

        # Apply KMeans clustering on the non-missing rows
        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)  # Set n_init to avoid warnings
        kmeans.fit(known_values.dropna(axis=1, how='all'))  # Drop columns that are completely NaN

        # Predict the clusters for missing values
        missing_values = df_copy_imputed[missing_mask].dropna(axis=1, how='all')  # Remove rows with all NaN values
        predicted_clusters = kmeans.predict(missing_values)  # Predict cluster for missing rows

        # Assign the cluster centers (mean values) to the missing rows
        imputed_values = kmeans.cluster_centers_[predicted_clusters]

        # Replace the missing values with the imputed ones
        df_copy_imputed.loc[missing_mask, column] = imputed_values

# Step 3: Now your dataframe has missing values imputed
print(df_copy_imputed.head())

# Print the encoded mappings for each column
print("column values and their encoded values")
for column, encoder in label_encoders.items():
    print(f"Column: {column}")
    for original, encoded in zip(encoder.classes_, encoder.transform(encoder.classes_)):
        print(f"  {original} -> {encoded}")
    print("\n")

for col in df_copy_imputed.columns:
    print(f"Column: {col}")
    print(df_copy_imputed[col].value_counts(dropna=False))  # Shows NaN count as well
    print("\n")

print(df_copy_imputed.value_counts(dropna=False))
print(df_copy_imputed.isna().sum())  # Check for any remaining NaNs

# Check the columns in the dataframe to ensure they are correct
print("Columns in DataFrame:", df_copy.columns)

# 1. One-Hot Encode categorical variables (except for 'Nightmare Frequency' and target)
categorical_columns = ['Nightmare Content', 'Parental Observations', 'Sleep Environment', 'Recent Life Changes']

# Check if all the columns in categorical_columns are in the dataframe
missing_columns = [col for col in categorical_columns if col not in df_copy.columns]
if missing_columns:
    print("Missing columns:", missing_columns)
else:
    # Proceed with one-hot encoding if all columns exist
    df_copy = pd.get_dummies(df_copy, columns=categorical_columns, drop_first=True)

print(df_copy['Age'].value_counts(dropna=False))  # Shows counts for each value, including NaN

# 2. Ordinal Encode 'Nightmare Frequency'
nightmare_frequency_map = {'Monthly': 0, 'Bi-weekly': 1, 'Weekly': 2}
df_copy['Nightmare Frequency'] = df_copy['Nightmare Frequency'].map(nightmare_frequency_map)

# Step 1: Map 'Age' categories to numeric values
age_map = {'4-5 years': 0, '6-7 years': 1, '8-10 years': 2}
df_copy['Age'] = df_copy['Age'].map(age_map)

# Step 2: Handle missing values for 'Age' by replacing NaN with the most frequent value
mode_age = df_copy['Age'].mode()
if not mode_age.empty:  # Ensure mode is not empty
    df_copy['Age'] = df_copy['Age'].fillna(mode_age[0])
else:
    print("No mode value found for Age column")
# Verify the changes
print(df_copy['Age'].unique())

# Map 'Sleep Patterns' to binary values
sleep_patterns_map = {'Irregular sleep': 0, 'Consistent sleep': 1,}

# Apply the mapping
df_copy['Sleep Patterns'] = df['Sleep Patterns'].map(sleep_patterns_map)

# Check the result
print(df_copy['Sleep Patterns'].unique())

# Binary encode 'Gender' column (Female = 0, Male = 1)
df_copy['Gender'] =df_copy['Gender'].map({'Female': 0, 'Male': 1})

# Verify the changes
print(df_copy['Gender'].unique())

# Convert all boolean columns (True/False) to 1/0
df_copy = df_copy.applymap(lambda x: 1 if x is True else (0 if x is False else x))

# Replace NaNs with 'Unknown' for categorical features
df_copy = df_copy.fillna('Unknown')

# 3. Label Encode the target variable 'Nightmare Frequency'
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df_copy['Nightmare Frequency'] = label_encoder.fit_transform(df_copy['Nightmare Frequency'])

# 4. Train-Test Split
X = df_copy_imputed.drop(columns=['Nightmare Frequency'])  # Drop target column from features
y = df_copy_imputed['Nightmare Frequency']

# Split into training and testing sets (80-20 split)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Now your data is preprocessed and ready for model training
print(f"Training data shape: {X_train.shape}")
print(f"Testing data shape: {X_test.shape}")

# Save the DataFrame to a CSV file
df.to_csv('/kaggle/working/preprocessed_data.csv', index=False)

# Print confirmation message
print("CSV file saved at /kaggle/working/preprocessed_data.csv")

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

for col in X_train.columns:
    print(f"Column: {col}")
    print(X_train[col].unique())  # Display all unique values in the column
    print("\n")

# 1. Train Logistic Regression Model
logreg = LogisticRegression(max_iter=200, random_state=42)  # Set max_iter to a higher number if convergence warning occurs
logreg.fit(X_train, y_train)

# 2. Make predictions on the test set
y_pred = logreg.predict(X_test)

# 3. Evaluate the model's performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

# Detailed performance report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))